{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n",
      "E:\\Anaconda3\\lib\\site-packages\\gensim\\utils.py:1197: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import keras\n",
    "from keras_tqdm import TQDMNotebookCallback\n",
    "import gensim\n",
    "import re\n",
    "from tqdm import tqdm,tqdm_notebook,tqdm_pandas\n",
    "import gc\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.snowball import RussianStemmer\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder, MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = 'E:/Kaggle/Avito/'\n",
    "REMOVE_NA_DESC = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_words = 100000\n",
    "max_len = 150\n",
    "seed = 32"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load word2vec dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "word2vec = gensim.models.Word2Vec.load(DATA_PATH+'avito300_sg.w2v')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(DATA_PATH+'train.csv')\n",
    "test = pd.read_csv(DATA_PATH+'test.csv')\n",
    "if REMOVE_NA_DESC:\n",
    "    train=train[train['description'].notnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_data = pd.concat([train,test],axis=0,ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_data['params']=complete_data['param_1'].astype(str)+complete_data['param_2'].astype(str)+complete_data['param_3'].astype(str)\n",
    "for col_text in ['params','title','description']:\n",
    "    complete_data[col_text].fillna('thisismissing',inplace=True)\n",
    "    complete_data[col_text] = complete_data[col_text].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_data['image_top_1'].fillna(-999,inplace=True)\n",
    "train['image_top_1'].fillna(-999,inplace=True)\n",
    "test['image_top_1'].fillna(-999,inplace=True)\n",
    "new_image_top = set(test['image_top_1'])-set(train['image_top_1'])\n",
    "complete_data['image_top_1']=np.where(complete_data['image_top_1'].isin(new_image_top),\n",
    "                                      -999,complete_data['image_top_1']) #should actually select the closest image class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_data['log_price']=np.log(complete_data['price']+1)\n",
    "complete_data['log_item_seq'] = np.log(1+complete_data['item_seq_number'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Categoricals as One Hot\n",
    "* Need to deal with missing values better.\n",
    "* Deal with low frequency categories and categories not in test set. Either impute it by something close that exists in train or by a new class\n",
    "* Try form of embedding instead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "categoricals_embs = ['region','parent_category_name','category_name','user_type','city',\n",
    "                     'image_top_1','user_id','param_1']\n",
    "dense = ['log_item_seq']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "catembs = []\n",
    "le=LabelEncoder()\n",
    "for cat in categoricals_embs: #Must deal with cities not in train set\n",
    "    complete_data[cat].fillna(-999,inplace=True)\n",
    "    complete_data[cat] = le.fit_transform(complete_data[cat].astype(str))\n",
    "    catembs.append(complete_data[cat].max()+1)\n",
    "X_categoricals = complete_data[categoricals_embs].values.astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[28, 9, 47, 3, 1752, 3063, 1009909, 372]\n"
     ]
    }
   ],
   "source": [
    "print(catembs) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Text stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "english_stopwords = set(stopwords.words('english'))\n",
    "russian_stopwords = set(stopwords.words('russian'))\n",
    "russian_stopwords = russian_stopwords.union(english_stopwords)\n",
    "def preprocess(x,stop_words=None):\n",
    "    x = keras.preprocessing.text.text_to_word_sequence(x)\n",
    "    if stop_words:\n",
    "        return [word for word in x if word not in russian_stopwords]\n",
    "    else:\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_token_matrix(data,text_col,num_words,max_len,stop_words=None):\n",
    "    \n",
    "    print('Create Tokenizer...',end=' ')\n",
    "    \n",
    "    texts = data[text_col].astype(str)\n",
    "    tokenizer = keras.preprocessing.text.Tokenizer(num_words=num_words,lower=True)\n",
    "    tokenizer.fit_on_texts(texts)\n",
    "    \n",
    "    print('Preprocess Text...',end=' ')\n",
    "    texts = texts.apply(lambda x: preprocess(x,stop_words))\n",
    "    \n",
    "    print('Create Matrix...',end=' ')\n",
    "    X = tokenizer.texts_to_sequences(texts)\n",
    "    X = keras.preprocessing.sequence.pad_sequences(X,padding='pre',truncating='post',maxlen=max_len)\n",
    "    \n",
    "    print('Done !')\n",
    "    return X,tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_data['description'] = complete_data['description'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create Tokenizer... Preprocess Text... Create Matrix... Done !\n"
     ]
    }
   ],
   "source": [
    "X_desc, tokenizer_desc = make_token_matrix(complete_data,'description',num_words,max_len,stop_words=russian_stopwords)\n",
    "word2idx = tokenizer_desc.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "word2idx = tokenizer_desc.word_index\n",
    "idx2word = {i:w for w,i in word2idx.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "кокон сна малыша пользовались меньше месяца цвет серый "
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Кокон для сна малыша,пользовались меньше месяца.цвет серый'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in X_desc[0]:\n",
    "    if i!=0:\n",
    "        print(idx2word[i],end=' ')\n",
    "complete_data.iloc[0]['description']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create Tokenizer... Preprocess Text... Create Matrix... Done !\n"
     ]
    }
   ],
   "source": [
    "X_title, tokenizer_title = make_token_matrix(complete_data,'title',num_words,max_len,stop_words=russian_stopwords)    \n",
    "word2idx_title = tokenizer_title.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create Tokenizer... Preprocess Text... Create Matrix... Done !\n"
     ]
    }
   ],
   "source": [
    "params_len = complete_data['params'].str.len().max()\n",
    "X_params, tokenizer_params = make_token_matrix(complete_data,'params',num_words,params_len)\n",
    "word2idx_params = tokenizer_params.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63\n"
     ]
    }
   ],
   "source": [
    "print(params_len)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dense features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_dense = scaler.fit_transform(complete_data[dense]).astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "dense_len = X_dense.shape[1]\n",
    "print(dense_len)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Concatenate and Splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "slices = [0, \n",
    "          max_len, #Description\n",
    "          max_len+max_len, #Title\n",
    "          max_len+max_len+params_len, #Params\n",
    "          max_len+max_len+params_len+dense_len, #Dense\n",
    "          *[max_len+max_len+params_len+dense_len+i+1 for i in range(len(catembs))]] #Categoricals as embeding layer \n",
    "\n",
    "slices_bounds = [(slices[i],slices[i+1]) for i,s in enumerate(slices) if i<len(slices)-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.concatenate([X_desc,X_title,X_params,X_dense,X_categoricals],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_index = complete_data['log_price'].isna()\n",
    "train_index = ~test_index\n",
    "\n",
    "X_tr = X[train_index].astype('float32')\n",
    "X_board = X[test_index].astype('float32')\n",
    "\n",
    "y = complete_data[train_index]['log_price']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_pretrain_embedding(w2idx,word2vec,embed_dim,num_words):\n",
    "    unknown_words = []\n",
    "    embeddings = np.zeros((num_words+1,embed_dim))  #0 is a special token\n",
    "    for word,idx in w2idx.items(): #starts at 1    \n",
    "        if idx>num_words:\n",
    "            break \n",
    "        try:\n",
    "            vect = word2vec[word]\n",
    "            embeddings[idx]=vect/np.linalg.norm(vect)\n",
    "        except KeyError:\n",
    "            unknown_words.append(word)\n",
    "    print('Number of words with no embeddings',len(unknown_words))\n",
    "    \n",
    "    return embeddings, unknown_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:8: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of words with no embeddings 211\n",
      "Number of words with no embeddings 7831\n"
     ]
    }
   ],
   "source": [
    "pretrained_desc, unknown_words1 = make_pretrain_embedding(word2idx,word2vec,300,num_words)\n",
    "pretrained_title, unknown_words2 = make_pretrain_embedding(word2idx_title,word2vec,300,num_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_cnn_model(desc_len,\n",
    "                   dense_len,\n",
    "                   params_len,\n",
    "                   catembs,\n",
    "                   embed_dim,\n",
    "                   pretrained_desc,pretrained_title,#pretrained_params,\n",
    "                   dropout=0,\n",
    "                   trainable_embeddings=False,\n",
    "                   conv_size=128):\n",
    "    \n",
    "    desc_input = keras.layers.Input(shape=(desc_len,))\n",
    "    title_input = keras.layers.Input(shape=(desc_len,))\n",
    "    params_input = keras.layers.Input(shape=(params_len,))\n",
    "    dense_input = keras.layers.Input(shape=(dense_len,))\n",
    "    pricechar_input = keras.layers.Input(shape=(10,))\n",
    "    \n",
    "    #Description part\n",
    "    embedded = keras.layers.Embedding(input_dim=pretrained_desc.shape[0],\n",
    "                                      output_dim=embed_dim,\n",
    "                                      input_length=max_len,\n",
    "                                      weights=[pretrained_desc],\n",
    "                                      trainable=trainable_embeddings)(desc_input)\n",
    "    \n",
    "    embedded = keras.layers.SpatialDropout1D(dropout+0.1)(embedded)\n",
    "    X_1 = keras.layers.Conv1D(conv_size,kernel_size=1,activation='relu')(embedded)\n",
    "    X_1 = keras.layers.GlobalMaxPooling1D()(X_1)\n",
    "    X_2 = keras.layers.Conv1D(conv_size,kernel_size=3,activation='relu')(embedded)\n",
    "    X_2 = keras.layers.GlobalMaxPooling1D()(X_2)\n",
    "    X_3 = keras.layers.Conv1D(conv_size,kernel_size=5,activation='relu')(embedded)\n",
    "    X_3 = keras.layers.GlobalMaxPooling1D()(X_3)\n",
    "    \n",
    "    desc_features = keras.layers.Concatenate()([X_1,X_2,X_3])\n",
    "    desc_features = keras.layers.Dropout(dropout+0.1)(desc_features)\n",
    "    desc_features = keras.layers.Dense(32,activation='relu')(desc_features)\n",
    "    \n",
    "    #Title\n",
    "    embedded_title = keras.layers.Embedding(input_dim=pretrained_title.shape[0],\n",
    "                                      output_dim=embed_dim,\n",
    "                                      input_length=max_len,\n",
    "                                      weights=[pretrained_title],\n",
    "                                      trainable=trainable_embeddings)(title_input)\n",
    "    \n",
    "    embedded_title = keras.layers.SpatialDropout1D(dropout+0.1)(embedded_title)\n",
    "    Z_1 = keras.layers.Conv1D(conv_size,kernel_size=1,activation='relu')(embedded_title)\n",
    "    Z_1 = keras.layers.GlobalMaxPooling1D()(Z_1)\n",
    "    Z_2 = keras.layers.Conv1D(conv_size,kernel_size=3,activation='relu')(embedded_title)\n",
    "    Z_2 = keras.layers.GlobalMaxPooling1D()(Z_2)\n",
    "    Z_3 = keras.layers.Conv1D(conv_size,kernel_size=5,activation='relu')(embedded_title)\n",
    "    Z_3 = keras.layers.GlobalMaxPooling1D()(Z_3)\n",
    "    \n",
    "    title_features = keras.layers.Concatenate()([Z_1,Z_2,Z_3])\n",
    "    title_features = keras.layers.Dropout(dropout+0.1)(title_features)\n",
    "    title_features = keras.layers.Dense(32,activation='relu')(title_features)\n",
    "    \n",
    "    #Params\n",
    "    embedded_params = keras.layers.Embedding(input_dim=len(tokenizer_params.word_index)+1,\n",
    "                                      output_dim=100,\n",
    "                                      input_length=params_len,trainable=True)(params_input)\n",
    "    params_features = keras.layers.CuDNNGRU(32,return_sequences=True)(embedded_params)\n",
    "    params_features = keras.layers.GlobalAveragePooling1D()(params_features)\n",
    "    \n",
    "    #Dense\n",
    "    dense_features = keras.layers.Dense(dense_len)(dense_input)\n",
    "    \n",
    "    #Categoricals    \n",
    "    cat_embs_inputs = []\n",
    "    cat_embs_embeded = []\n",
    "    for i in range(len(catembs)):\n",
    "        cat_embs_inputs.append(keras.layers.Input(shape=(1,)))\n",
    "        cat_embs_embeded.append(keras.layers.Embedding(input_dim=catembs[i],\n",
    "                                                      output_dim=16,\n",
    "                                                      input_length=1,trainable=True)(cat_embs_inputs[i]))\n",
    "    \n",
    "    cat_emb_features = keras.layers.Concatenate()(cat_embs_embeded)\n",
    "    cat_emb_features = keras.layers.Flatten()(cat_emb_features)\n",
    "    cat_emb_features = keras.layers.Dropout(dropout)(cat_emb_features)\n",
    "    cat_emb_features = keras.layers.Dense(128,activation='relu')(cat_emb_features)\n",
    "    cat_emb_features = keras.layers.Dropout(dropout)(cat_emb_features)\n",
    "    cat_emb_features = keras.layers.Dense(32,activation='relu')(cat_emb_features)\n",
    "    \n",
    "    #Concatenate Features\n",
    "    X = keras.layers.Concatenate()([cat_emb_features,desc_features,title_features,params_features,dense_features])\n",
    "    X = keras.layers.Dropout(dropout+0.1)(X)\n",
    "    X = keras.layers.Dense(256,activation='relu')(X)\n",
    "    X = keras.layers.Dropout(dropout)(X)\n",
    "    X = keras.layers.Dense(128,activation='relu')(X)\n",
    "    X = keras.layers.Dense(32,activation='tanh')(X)\n",
    "    \n",
    "    y_hat = keras.layers.Dense(1)(X)\n",
    "    \n",
    "    cnn_model = keras.Model(inputs=[desc_input,title_input,params_input,dense_input,*cat_embs_inputs],outputs=y_hat)\n",
    "    \n",
    "    return cnn_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a621c226f7384b18905f4d45535505b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Training', max=2), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "73847623b381451d806e54b208636dc8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 0', max=1895915), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "95a1d5aedf8b4445a13a5d73fc488977",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 1', max=1895915), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "gc.collect()\n",
    "np.random.seed(seed)\n",
    "\n",
    "\n",
    "VALID=False\n",
    "if VALID:\n",
    "    X_tr_tr, X_val, y_tr, y_val = train_test_split(X_tr,y,test_size=0.1,random_state=seed)\n",
    "    keras.backend.clear_session() #Reset   \n",
    "    cnn_model = make_cnn_model(max_len,\n",
    "                               dense_len,\n",
    "                               params_len,\n",
    "                               catembs,\n",
    "                               300,\n",
    "                               pretrained_desc,pretrained_title,\n",
    "                               dropout=0.3,\n",
    "                               trainable_embeddings=False, conv_size=128) #If allows train of embedding words, will have to restrict vocab to the train set\n",
    "    Adam = keras.optimizers.Adam(0.001)\n",
    "    cnn_model.compile(optimizer=Adam,loss='mean_squared_error')\n",
    "    epochs = 20 #Beware of overfit\n",
    "    cnn_model.fit([X_tr_tr[:,s[0]:s[1]] for s in slices_bounds],\n",
    "              y_tr,\n",
    "              validation_data=([X_val[:,s[0]:s[1]] for s in slices_bounds], y_val),\n",
    "              batch_size=512,epochs=epochs,verbose = 0,callbacks=[TQDMNotebookCallback(leave_inner=True)],)\n",
    "    predictions = cnn_model.predict([X_val[:,s[0]:s[1]] for s in slices_bounds]).flatten()\n",
    "    r = np.sqrt(np.mean((predictions.clip(0,1)-y_val)**2))\n",
    "    print(f'RMSE : {r:.4f}')\n",
    "    \n",
    "else:\n",
    "    \n",
    "    cnn_model = make_cnn_model(max_len,\n",
    "                           dense_len,\n",
    "                           params_len,\n",
    "                           catembs,\n",
    "                           300,\n",
    "                           pretrained_desc,pretrained_title,\n",
    "                           dropout=0.3,\n",
    "                           trainable_embeddings=False, conv_size=128) #If allows train of embedding words, will have to restrict vocab to the train set\n",
    "    Adam = keras.optimizers.Adam(0.001)\n",
    "    cnn_model.compile(optimizer=Adam,loss='mean_squared_error')\n",
    "    epochs = 2 #Beware of overfit\n",
    "    cnn_model.fit([X_tr[:,s[0]:s[1]] for s in slices_bounds],\n",
    "              y,\n",
    "              batch_size=512,epochs=epochs,verbose = 0,callbacks=[TQDMNotebookCallback(leave_inner=True)],)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "guess_price = complete_data[['item_id']].copy()\n",
    "guess_price['Guess_price'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in range(21):\n",
    "    X_batch = X[100000*k:100000*(k+1),:]\n",
    "    predictions_price = cnn_model.predict([X_batch[:,s[0]:s[1]] for s in slices_bounds])\n",
    "    guess_price.iloc[100000*k:100000*(k+1),1]=predictions_price.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "guess_price.to_csv(DATA_PATH+'price_guess.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "guess_price['real_log_price']=complete_data['log_price']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item_id</th>\n",
       "      <th>Guess_price</th>\n",
       "      <th>real_log_price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>b912c3c6a6ad</td>\n",
       "      <td>6.510823</td>\n",
       "      <td>5.993961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2dac0150717d</td>\n",
       "      <td>7.904475</td>\n",
       "      <td>8.006701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ba83aefab5dc</td>\n",
       "      <td>7.189164</td>\n",
       "      <td>8.294300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>02996f1dd2ea</td>\n",
       "      <td>7.594705</td>\n",
       "      <td>7.696667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7c90be56d2ab</td>\n",
       "      <td>10.731431</td>\n",
       "      <td>10.596660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>51e0962387f7</td>\n",
       "      <td>7.174815</td>\n",
       "      <td>7.170888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>c4f260a2b48a</td>\n",
       "      <td>8.181076</td>\n",
       "      <td>9.305741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>6b71309d6a8a</td>\n",
       "      <td>6.173020</td>\n",
       "      <td>6.216606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>c5b969cb63a2</td>\n",
       "      <td>6.380401</td>\n",
       "      <td>6.216606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>b1570962e68c</td>\n",
       "      <td>6.002148</td>\n",
       "      <td>5.993961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>d5480bb4a6e4</td>\n",
       "      <td>9.533937</td>\n",
       "      <td>9.798183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>86f41f50d8c1</td>\n",
       "      <td>5.433472</td>\n",
       "      <td>0.693147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>645237cb3601</td>\n",
       "      <td>4.387750</td>\n",
       "      <td>4.262680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>df2116f34563</td>\n",
       "      <td>7.498769</td>\n",
       "      <td>7.824446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>a97943ae8158</td>\n",
       "      <td>8.530659</td>\n",
       "      <td>8.517393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>4b6abd0a5921</td>\n",
       "      <td>7.136013</td>\n",
       "      <td>6.685861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>7896ef8fe482</td>\n",
       "      <td>11.940927</td>\n",
       "      <td>11.849405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>7882b1e77748</td>\n",
       "      <td>6.691113</td>\n",
       "      <td>6.216606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>071e1ed13c5c</td>\n",
       "      <td>7.040628</td>\n",
       "      <td>6.908755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0658628930d4</td>\n",
       "      <td>9.716380</td>\n",
       "      <td>11.512935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>ea12aec32ec3</td>\n",
       "      <td>14.509922</td>\n",
       "      <td>14.373983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>838a82cec0a6</td>\n",
       "      <td>7.574270</td>\n",
       "      <td>7.863651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>de310e6aae86</td>\n",
       "      <td>12.181241</td>\n",
       "      <td>12.425212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>08b24e170109</td>\n",
       "      <td>7.397196</td>\n",
       "      <td>7.170888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>065a4daba35f</td>\n",
       "      <td>6.182127</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>990113ae4f1c</td>\n",
       "      <td>6.291842</td>\n",
       "      <td>7.313887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>78164bc09657</td>\n",
       "      <td>6.820823</td>\n",
       "      <td>6.908755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>fbe29970a8a5</td>\n",
       "      <td>6.877518</td>\n",
       "      <td>7.313887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>71d9399b59a2</td>\n",
       "      <td>6.896960</td>\n",
       "      <td>6.908755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>4941f0385575</td>\n",
       "      <td>5.944083</td>\n",
       "      <td>5.303305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011832</th>\n",
       "      <td>df8001ca5897</td>\n",
       "      <td>8.920059</td>\n",
       "      <td>10.085851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011833</th>\n",
       "      <td>0455281c86fb</td>\n",
       "      <td>6.268280</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011834</th>\n",
       "      <td>482d3253c9f1</td>\n",
       "      <td>7.298375</td>\n",
       "      <td>9.686637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011835</th>\n",
       "      <td>9278e7c14cd0</td>\n",
       "      <td>6.925162</td>\n",
       "      <td>6.552508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011836</th>\n",
       "      <td>9041d0340b49</td>\n",
       "      <td>7.008305</td>\n",
       "      <td>6.216606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011837</th>\n",
       "      <td>872c382ce446</td>\n",
       "      <td>7.417577</td>\n",
       "      <td>7.596392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011838</th>\n",
       "      <td>67448ad8941c</td>\n",
       "      <td>5.506311</td>\n",
       "      <td>5.017280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011839</th>\n",
       "      <td>6ffaf4c20469</td>\n",
       "      <td>6.470261</td>\n",
       "      <td>5.860786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011840</th>\n",
       "      <td>acc46dbda733</td>\n",
       "      <td>9.272416</td>\n",
       "      <td>9.952325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011841</th>\n",
       "      <td>eb33cd6dac70</td>\n",
       "      <td>6.129637</td>\n",
       "      <td>5.707110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011842</th>\n",
       "      <td>f9db673cb425</td>\n",
       "      <td>7.028260</td>\n",
       "      <td>7.313887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011843</th>\n",
       "      <td>32727c2ed7e5</td>\n",
       "      <td>3.796444</td>\n",
       "      <td>3.433987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011844</th>\n",
       "      <td>2e6f289d2676</td>\n",
       "      <td>6.514456</td>\n",
       "      <td>7.003974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011845</th>\n",
       "      <td>58fa2c39f791</td>\n",
       "      <td>9.441586</td>\n",
       "      <td>9.680406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011846</th>\n",
       "      <td>0e1a370c12c7</td>\n",
       "      <td>7.513314</td>\n",
       "      <td>7.824446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011847</th>\n",
       "      <td>cc4f7fd3d2f2</td>\n",
       "      <td>6.845229</td>\n",
       "      <td>6.965080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011848</th>\n",
       "      <td>29a342aa8508</td>\n",
       "      <td>8.714025</td>\n",
       "      <td>9.210440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011849</th>\n",
       "      <td>fce6b0de65f8</td>\n",
       "      <td>6.229982</td>\n",
       "      <td>5.707110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011850</th>\n",
       "      <td>dae17c1850b0</td>\n",
       "      <td>8.657187</td>\n",
       "      <td>8.517393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011851</th>\n",
       "      <td>549b1c9354e3</td>\n",
       "      <td>7.145146</td>\n",
       "      <td>7.313887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011852</th>\n",
       "      <td>0915772bb21c</td>\n",
       "      <td>6.129986</td>\n",
       "      <td>5.525453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011853</th>\n",
       "      <td>d8984ced6639</td>\n",
       "      <td>9.078659</td>\n",
       "      <td>9.546884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011854</th>\n",
       "      <td>e7c68be28a03</td>\n",
       "      <td>6.057707</td>\n",
       "      <td>8.006701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011855</th>\n",
       "      <td>a96a4c5ad75a</td>\n",
       "      <td>6.495947</td>\n",
       "      <td>6.216606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011856</th>\n",
       "      <td>fdcd9910edf3</td>\n",
       "      <td>12.976002</td>\n",
       "      <td>12.542548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011857</th>\n",
       "      <td>9f2200aed300</td>\n",
       "      <td>6.633020</td>\n",
       "      <td>7.090910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011858</th>\n",
       "      <td>70813f518de4</td>\n",
       "      <td>9.402361</td>\n",
       "      <td>10.239996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011859</th>\n",
       "      <td>a22a2eeb5dd2</td>\n",
       "      <td>6.768082</td>\n",
       "      <td>6.803505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011860</th>\n",
       "      <td>ed7fbb0733c1</td>\n",
       "      <td>6.736773</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011861</th>\n",
       "      <td>d374d332992f</td>\n",
       "      <td>7.413291</td>\n",
       "      <td>7.596392</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2011862 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              item_id  Guess_price  real_log_price\n",
       "0        b912c3c6a6ad     6.510823        5.993961\n",
       "1        2dac0150717d     7.904475        8.006701\n",
       "2        ba83aefab5dc     7.189164        8.294300\n",
       "3        02996f1dd2ea     7.594705        7.696667\n",
       "4        7c90be56d2ab    10.731431       10.596660\n",
       "5        51e0962387f7     7.174815        7.170888\n",
       "6        c4f260a2b48a     8.181076        9.305741\n",
       "7        6b71309d6a8a     6.173020        6.216606\n",
       "8        c5b969cb63a2     6.380401        6.216606\n",
       "9        b1570962e68c     6.002148        5.993961\n",
       "10       d5480bb4a6e4     9.533937        9.798183\n",
       "11       86f41f50d8c1     5.433472        0.693147\n",
       "12       645237cb3601     4.387750        4.262680\n",
       "13       df2116f34563     7.498769        7.824446\n",
       "14       a97943ae8158     8.530659        8.517393\n",
       "15       4b6abd0a5921     7.136013        6.685861\n",
       "16       7896ef8fe482    11.940927       11.849405\n",
       "17       7882b1e77748     6.691113        6.216606\n",
       "18       071e1ed13c5c     7.040628        6.908755\n",
       "19       0658628930d4     9.716380       11.512935\n",
       "20       ea12aec32ec3    14.509922       14.373983\n",
       "21       838a82cec0a6     7.574270        7.863651\n",
       "22       de310e6aae86    12.181241       12.425212\n",
       "23       08b24e170109     7.397196        7.170888\n",
       "24       065a4daba35f     6.182127             NaN\n",
       "25       990113ae4f1c     6.291842        7.313887\n",
       "26       78164bc09657     6.820823        6.908755\n",
       "27       fbe29970a8a5     6.877518        7.313887\n",
       "28       71d9399b59a2     6.896960        6.908755\n",
       "29       4941f0385575     5.944083        5.303305\n",
       "...               ...          ...             ...\n",
       "2011832  df8001ca5897     8.920059       10.085851\n",
       "2011833  0455281c86fb     6.268280             NaN\n",
       "2011834  482d3253c9f1     7.298375        9.686637\n",
       "2011835  9278e7c14cd0     6.925162        6.552508\n",
       "2011836  9041d0340b49     7.008305        6.216606\n",
       "2011837  872c382ce446     7.417577        7.596392\n",
       "2011838  67448ad8941c     5.506311        5.017280\n",
       "2011839  6ffaf4c20469     6.470261        5.860786\n",
       "2011840  acc46dbda733     9.272416        9.952325\n",
       "2011841  eb33cd6dac70     6.129637        5.707110\n",
       "2011842  f9db673cb425     7.028260        7.313887\n",
       "2011843  32727c2ed7e5     3.796444        3.433987\n",
       "2011844  2e6f289d2676     6.514456        7.003974\n",
       "2011845  58fa2c39f791     9.441586        9.680406\n",
       "2011846  0e1a370c12c7     7.513314        7.824446\n",
       "2011847  cc4f7fd3d2f2     6.845229        6.965080\n",
       "2011848  29a342aa8508     8.714025        9.210440\n",
       "2011849  fce6b0de65f8     6.229982        5.707110\n",
       "2011850  dae17c1850b0     8.657187        8.517393\n",
       "2011851  549b1c9354e3     7.145146        7.313887\n",
       "2011852  0915772bb21c     6.129986        5.525453\n",
       "2011853  d8984ced6639     9.078659        9.546884\n",
       "2011854  e7c68be28a03     6.057707        8.006701\n",
       "2011855  a96a4c5ad75a     6.495947        6.216606\n",
       "2011856  fdcd9910edf3    12.976002       12.542548\n",
       "2011857  9f2200aed300     6.633020        7.090910\n",
       "2011858  70813f518de4     9.402361       10.239996\n",
       "2011859  a22a2eeb5dd2     6.768082        6.803505\n",
       "2011860  ed7fbb0733c1     6.736773             NaN\n",
       "2011861  d374d332992f     7.413291        7.596392\n",
       "\n",
       "[2011862 rows x 3 columns]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "guess_price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
