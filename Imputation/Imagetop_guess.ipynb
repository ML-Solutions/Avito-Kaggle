{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Changes:\n",
    "* All categoricals as embedding\n",
    "\n",
    "Things to add :\n",
    "1. Add categoricals\n",
    "    * First as one encoding\n",
    "    * Second as vectorized version based on other variables like price\n",
    "    * Third try to do also encoding of the target (Beware of cross validation)\n",
    "2. Add dense features (This is where to put encodings)\n",
    "    * Dont forget to scale (with train+test)\n",
    "3. Add title features\n",
    "4. Add Regularization !\n",
    "5. Add Emoji detection (character tokenizer)\n",
    "6. Use desc/title features as extra variables in a tree\n",
    "6. Add extra features found in other notebooks\n",
    "\n",
    "Don't forget to normalize.\n",
    "Try SnowballStemmer in Russian\n",
    "\n",
    "CNN 10 epochs:\n",
    "* desc : 0.235\n",
    "* desc + region + pcn : 0.233\n",
    "* desc + region + pcn + cn : 0.231\n",
    "* desc + region + pcn + cn + ut : 0.230\n",
    "* desc + region + pcn + cn + ut + title : 0.227\n",
    "* desc + region + pcn + cn + ut + title + image_top + city : 0.224\n",
    "* desc + region + pcn + cn + ut + title + image_top + city + logprice + price_char : 0.223\n",
    "* desc + region + pcn + cn + ut + title + image_top + city + logprice + price_char + Params : 0.221\n",
    "* desc + region + pcn + cn + ut + title + image_top + city + logprice + price_char + Params + User_id + Weekday : 0.2206\n",
    "* ###1### = desc + region + pcn + cn + ut + title + image_top + city + logprice + price_char + Params + User_id + Param_1 + logItem_seq : 0.2194\n",
    "* ###1### + Encodings : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n",
      "E:\\Anaconda3\\lib\\site-packages\\gensim\\utils.py:1197: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import keras\n",
    "from keras_tqdm import TQDMNotebookCallback\n",
    "import gensim\n",
    "import re\n",
    "from tqdm import tqdm,tqdm_notebook,tqdm_pandas\n",
    "import gc\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.snowball import RussianStemmer\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder, MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = 'E:/Kaggle/Avito/'\n",
    "REMOVE_NA_DESC = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_words = 100000\n",
    "max_len = 150\n",
    "seed = 32"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load word2vec dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "word2vec = gensim.models.Word2Vec.load(DATA_PATH+'avito300_sg.w2v')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(DATA_PATH+'train.csv')\n",
    "test = pd.read_csv(DATA_PATH+'test.csv')\n",
    "if REMOVE_NA_DESC:\n",
    "    train=train[train['description'].notnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_data = pd.concat([train,test],axis=0,ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_data['params']=complete_data['param_1'].astype(str)+complete_data['param_2'].astype(str)+complete_data['param_3'].astype(str)\n",
    "for col_text in ['params','title','description']:\n",
    "    complete_data[col_text].fillna('thisismissing',inplace=True)\n",
    "    complete_data[col_text] = complete_data[col_text].astype(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Categoricals as One Hot\n",
    "* Need to deal with missing values better.\n",
    "* Deal with low frequency categories and categories not in test set. Either impute it by something close that exists in train or by a new class\n",
    "* Try form of embedding instead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "categoricals_embs = ['parent_category_name','category_name','param_1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "catembs = []\n",
    "le=LabelEncoder()\n",
    "for cat in categoricals_embs: #Must deal with cities not in train set\n",
    "    complete_data[cat].fillna(-999,inplace=True)\n",
    "    complete_data[cat] = le.fit_transform(complete_data[cat].astype(str))\n",
    "    catembs.append(complete_data[cat].max()+1)\n",
    "X_categoricals = complete_data[categoricals_embs].values.astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9, 47, 372]\n"
     ]
    }
   ],
   "source": [
    "print(catembs) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Text stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "english_stopwords = set(stopwords.words('english'))\n",
    "russian_stopwords = set(stopwords.words('russian'))\n",
    "russian_stopwords = russian_stopwords.union(english_stopwords)\n",
    "def preprocess(x,stop_words=None):\n",
    "    x = keras.preprocessing.text.text_to_word_sequence(x)\n",
    "    if stop_words:\n",
    "        return [word for word in x if word not in russian_stopwords]\n",
    "    else:\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_token_matrix(data,text_col,num_words,max_len,stop_words=None):\n",
    "    \n",
    "    print('Create Tokenizer...',end=' ')\n",
    "    \n",
    "    texts = data[text_col].astype(str)\n",
    "    tokenizer = keras.preprocessing.text.Tokenizer(num_words=num_words,lower=True)\n",
    "    tokenizer.fit_on_texts(texts)\n",
    "    \n",
    "    print('Preprocess Text...',end=' ')\n",
    "    texts = texts.apply(lambda x: preprocess(x,stop_words))\n",
    "    \n",
    "    print('Create Matrix...',end=' ')\n",
    "    X = tokenizer.texts_to_sequences(texts)\n",
    "    X = keras.preprocessing.sequence.pad_sequences(X,padding='pre',truncating='post',maxlen=max_len)\n",
    "    \n",
    "    print('Done !')\n",
    "    return X,tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_data['description'] = complete_data['description'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create Tokenizer... Preprocess Text... Create Matrix... Done !\n"
     ]
    }
   ],
   "source": [
    "X_desc, tokenizer_desc = make_token_matrix(complete_data,'description',num_words,max_len,stop_words=russian_stopwords)\n",
    "word2idx = tokenizer_desc.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "word2idx = tokenizer_desc.word_index\n",
    "idx2word = {i:w for w,i in word2idx.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "кокон сна малыша пользовались меньше месяца цвет серый "
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Кокон для сна малыша,пользовались меньше месяца.цвет серый'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in X_desc[0]:\n",
    "    if i!=0:\n",
    "        print(idx2word[i],end=' ')\n",
    "complete_data.iloc[0]['description']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create Tokenizer... Preprocess Text... Create Matrix... Done !\n"
     ]
    }
   ],
   "source": [
    "X_title, tokenizer_title = make_token_matrix(complete_data,'title',num_words,max_len,stop_words=russian_stopwords)    \n",
    "word2idx_title = tokenizer_title.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create Tokenizer... Preprocess Text... Create Matrix... Done !\n"
     ]
    }
   ],
   "source": [
    "params_len = complete_data['params'].str.len().max()\n",
    "X_params, tokenizer_params = make_token_matrix(complete_data,'params',num_words,params_len)\n",
    "word2idx_params = tokenizer_params.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63\n"
     ]
    }
   ],
   "source": [
    "print(params_len)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Concatenate and Splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "slices = [0, \n",
    "          max_len, #Description\n",
    "          max_len+max_len, #Title\n",
    "          max_len+max_len+params_len, #Params\n",
    "          *[max_len+max_len+params_len+i+1 for i in range(len(catembs))]] #Categoricals as embeding layer \n",
    "\n",
    "slices_bounds = [(slices[i],slices[i+1]) for i,s in enumerate(slices) if i<len(slices)-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 150), (150, 300), (300, 363), (363, 364), (364, 365), (365, 366)]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "slices_bounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.concatenate([X_desc,X_title,X_params,X_categoricals],axis=1)\n",
    "#del X_title\n",
    "#del X_params\n",
    "#del X_dense\n",
    "#del X_price\n",
    "#del X_desc\n",
    "#del X_categoricals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_index = complete_data['image_top_1'].isna()\n",
    "train_index = ~test_index\n",
    "\n",
    "X_tr = X[train_index].astype('float32')\n",
    "X_board = X[test_index].astype('float32')\n",
    "\n",
    "y = complete_data[train_index]['image_top_1']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_pretrain_embedding(w2idx,word2vec,embed_dim,num_words):\n",
    "    unknown_words = []\n",
    "    embeddings = np.zeros((num_words+1,embed_dim))  #0 is a special token\n",
    "    for word,idx in w2idx.items(): #starts at 1    \n",
    "        if idx>num_words:\n",
    "            break \n",
    "        try:\n",
    "            vect = word2vec[word]\n",
    "            embeddings[idx]=vect/np.linalg.norm(vect)\n",
    "        except KeyError:\n",
    "            unknown_words.append(word)\n",
    "    print('Number of words with no embeddings',len(unknown_words))\n",
    "    \n",
    "    return embeddings, unknown_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:8: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of words with no embeddings 211\n",
      "Number of words with no embeddings 7831\n"
     ]
    }
   ],
   "source": [
    "pretrained_desc, unknown_words1 = make_pretrain_embedding(word2idx,word2vec,300,num_words)\n",
    "pretrained_title, unknown_words2 = make_pretrain_embedding(word2idx_title,word2vec,300,num_words)\n",
    "#pretrained_params = make_pretrain_embedding(word2idx_params,word2vec,300,num_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3063"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_cnn_model(desc_len,\n",
    "                   params_len,\n",
    "                   catembs,\n",
    "                   embed_dim,\n",
    "                   pretrained_desc,pretrained_title,#pretrained_params,\n",
    "                   dropout=0,\n",
    "                   trainable_embeddings=False,\n",
    "                   conv_size=128):\n",
    "    \n",
    "    desc_input = keras.layers.Input(shape=(desc_len,))\n",
    "    title_input = keras.layers.Input(shape=(desc_len,))\n",
    "    params_input = keras.layers.Input(shape=(params_len,))\n",
    "    \n",
    "    #Description part\n",
    "    embedded = keras.layers.Embedding(input_dim=pretrained_desc.shape[0],\n",
    "                                      output_dim=embed_dim,\n",
    "                                      input_length=max_len,\n",
    "                                      weights=[pretrained_desc],\n",
    "                                      trainable=trainable_embeddings)(desc_input)\n",
    "    \n",
    "    embedded = keras.layers.SpatialDropout1D(dropout+0.1)(embedded)\n",
    "    X_1 = keras.layers.Conv1D(conv_size,kernel_size=1,activation='relu')(embedded)\n",
    "    X_1 = keras.layers.GlobalMaxPooling1D()(X_1)\n",
    "    X_2 = keras.layers.Conv1D(conv_size,kernel_size=3,activation='relu')(embedded)\n",
    "    X_2 = keras.layers.GlobalMaxPooling1D()(X_2)\n",
    "    X_3 = keras.layers.Conv1D(conv_size,kernel_size=5,activation='relu')(embedded)\n",
    "    X_3 = keras.layers.GlobalMaxPooling1D()(X_3)\n",
    "    \n",
    "    desc_features = keras.layers.Concatenate()([X_1,X_2,X_3])\n",
    "    desc_features = keras.layers.Dropout(dropout+0.1)(desc_features)\n",
    "    desc_features = keras.layers.Dense(32,activation='relu')(desc_features)\n",
    "    \n",
    "    #Title\n",
    "    embedded_title = keras.layers.Embedding(input_dim=pretrained_title.shape[0],\n",
    "                                      output_dim=embed_dim,\n",
    "                                      input_length=max_len,\n",
    "                                      weights=[pretrained_title],\n",
    "                                      trainable=trainable_embeddings)(title_input)\n",
    "    \n",
    "    embedded_title = keras.layers.SpatialDropout1D(dropout+0.1)(embedded_title)\n",
    "    Z_1 = keras.layers.Conv1D(conv_size,kernel_size=1,activation='relu')(embedded_title)\n",
    "    Z_1 = keras.layers.GlobalMaxPooling1D()(Z_1)\n",
    "    Z_2 = keras.layers.Conv1D(conv_size,kernel_size=3,activation='relu')(embedded_title)\n",
    "    Z_2 = keras.layers.GlobalMaxPooling1D()(Z_2)\n",
    "    Z_3 = keras.layers.Conv1D(conv_size,kernel_size=5,activation='relu')(embedded_title)\n",
    "    Z_3 = keras.layers.GlobalMaxPooling1D()(Z_3)\n",
    "    \n",
    "    title_features = keras.layers.Concatenate()([Z_1,Z_2,Z_3])\n",
    "    title_features = keras.layers.Dropout(dropout+0.1)(title_features)\n",
    "    title_features = keras.layers.Dense(32,activation='relu')(title_features)\n",
    "    \n",
    "    #Params\n",
    "    embedded_params = keras.layers.Embedding(input_dim=len(tokenizer_params.word_index)+1,\n",
    "                                      output_dim=100,\n",
    "                                      input_length=params_len,trainable=True)(params_input)\n",
    "    params_features = keras.layers.CuDNNGRU(32,return_sequences=True)(embedded_params)\n",
    "    params_avg = keras.layers.GlobalAveragePooling1D()(params_features)\n",
    "    params_max = keras.layers.GlobalMaxPooling1D()(params_features)\n",
    "    params_features = keras.layers.Concatenate()([params_avg,params_max])\n",
    "    \n",
    "    #Categoricals    \n",
    "    cat_embs_inputs = []\n",
    "    cat_embs_embeded = []\n",
    "    for i in range(len(catembs)):\n",
    "        cat_embs_inputs.append(keras.layers.Input(shape=(1,)))\n",
    "        cat_embs_embeded.append(keras.layers.Embedding(input_dim=catembs[i],\n",
    "                                                      output_dim=16,\n",
    "                                                      input_length=1,trainable=True)(cat_embs_inputs[i]))\n",
    "    \n",
    "    cat_emb_features = keras.layers.Concatenate()(cat_embs_embeded)\n",
    "    cat_emb_features = keras.layers.Flatten()(cat_emb_features)\n",
    "    cat_emb_features = keras.layers.Dropout(dropout)(cat_emb_features)\n",
    "    cat_emb_features = keras.layers.Dense(128,activation='relu')(cat_emb_features)\n",
    "    cat_emb_features = keras.layers.Dropout(dropout)(cat_emb_features)\n",
    "    cat_emb_features = keras.layers.Dense(32,activation='relu')(cat_emb_features)\n",
    "    \n",
    "    #Concatenate Features\n",
    "    X = keras.layers.Concatenate()([cat_emb_features,desc_features,title_features,params_features])\n",
    "    X = keras.layers.Dropout(dropout+0.1)(X)\n",
    "    X = keras.layers.Dense(256,activation='relu')(X)\n",
    "    X = keras.layers.Dropout(dropout)(X)\n",
    "    X = keras.layers.Dense(128,activation='relu')(X)\n",
    "    X = keras.layers.BatchNormalization()(X)\n",
    "    \n",
    "    y_hat = keras.layers.Dense(3067,activation='softmax')(X)\n",
    "    \n",
    "    cnn_model = keras.Model(inputs=[desc_input,title_input,params_input,*cat_embs_inputs],outputs=y_hat)\n",
    "    \n",
    "    return cnn_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From E:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\deprecation.py:497: calling conv1d (from tensorflow.python.ops.nn_ops) with data_format=NHWC is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "`NHWC` for data_format is deprecated, use `NWC` instead\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e836608282a49aebc6a2c428ee25171",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Training', max=10), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "350ef1b2ee37449c9c620f78a1ff986b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 0', max=1856665), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf5fc165606e42638c2eb65be2a84487",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 1', max=1856665), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b7a55b736dac40fcbec01185b95a1eb4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 2', max=1856665), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "429e57c9d0ce4135a1398fb136d3b372",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 3', max=1856665), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "25e09eae3fdb4ebaa79394290e9977d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 4', max=1856665), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c2dcae42d746453c968dacf9f3e34fe8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 5', max=1856665), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2447ad6f85734246ba55ed0101066764",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 6', max=1856665), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a61463fe7d7455fa555dba630026387",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 7', max=1856665), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1bb9a9b5939441e093cdfb1f76cbacc0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 8', max=1856665), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "55b763b73f594e7dae6dbe18a403aa09",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 9', max=1856665), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "gc.collect()\n",
    "np.random.seed(seed)\n",
    "VALID=False\n",
    "if VALID:\n",
    "    X_tr_tr, X_val, y_tr, y_val = train_test_split(X_tr,y,test_size=0.1,random_state=seed)\n",
    "    keras.backend.clear_session() #Reset   \n",
    "    cnn_model = make_cnn_model(max_len,\n",
    "                               params_len,\n",
    "                               catembs,\n",
    "                               300,\n",
    "                               pretrained_desc,pretrained_title,\n",
    "                               dropout=0.2,\n",
    "                               trainable_embeddings=False, conv_size=128) #If allows train of embedding words, will have to restrict vocab to the train set\n",
    "    Adam = keras.optimizers.Adam(0.001)\n",
    "    cnn_model.compile(optimizer=Adam,loss=keras.losses.sparse_categorical_crossentropy,metrics=['accuracy'])\n",
    "    epochs = 10 #Beware of overfit\n",
    "    cnn_model.fit([X_tr_tr[:,s[0]:s[1]] for s in slices_bounds],\n",
    "              y_tr,\n",
    "              validation_data=([X_val[:,s[0]:s[1]] for s in slices_bounds], y_val),\n",
    "              batch_size=512,epochs=epochs,verbose = 0,callbacks=[TQDMNotebookCallback(leave_inner=True)],)\n",
    "    predictions = cnn_model.predict([X_val[:,s[0]:s[1]] for s in slices_bounds]).flatten()\n",
    "    r = np.sqrt(np.mean((predictions.clip(0,1)-y_val)**2))\n",
    "    print(f'RMSE : {r:.4f}')\n",
    "    \n",
    "else:\n",
    "    cnn_model = make_cnn_model(max_len,\n",
    "                           params_len,\n",
    "                           catembs,\n",
    "                           300,\n",
    "                           pretrained_desc,pretrained_title,\n",
    "                           dropout=0.2,\n",
    "                           trainable_embeddings=False, conv_size=128) #If allows train of embedding words, will have to restrict vocab to the train set\n",
    "    Adam = keras.optimizers.Adam(0.001)\n",
    "    cnn_model.compile(optimizer=Adam,loss=keras.losses.sparse_categorical_crossentropy,metrics=['accuracy'])\n",
    "    epochs = 10 #Beware of overfit\n",
    "    cnn_model.fit([X_tr[:,s[0]:s[1]] for s in slices_bounds],\n",
    "              y,\n",
    "              batch_size=512,epochs=epochs,verbose = 0,callbacks=[TQDMNotebookCallback(leave_inner=True)],)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "guess_image = complete_data[['item_id']].copy()\n",
    "guess_image['Prob_image_top1'] = 0\n",
    "guess_image['Guess_image_top1'] = 0\n",
    "guess_image['Guess_image_top2'] = 0\n",
    "guess_image['Guess_image_top3'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in range(41):\n",
    "    X_batch = X[50000*k:50000*(k+1),:]\n",
    "    predictions_image = cnn_model.predict([X_batch[:,s[0]:s[1]] for s in slices_bounds])\n",
    "    guess_image.iloc[50000*k:50000*(k+1),1]=predictions_image.max(axis=1)\n",
    "    guess_image.iloc[50000*k:50000*(k+1),2]=predictions_image.argmax(axis=1)\n",
    "    predictions_image = predictions_image.argsort(axis=1)\n",
    "    guess_image.iloc[50000*k:50000*(k+1),3]=predictions_image[:,-2:-1]\n",
    "    guess_image.iloc[50000*k:50000*(k+1),4]=predictions_image[:,-3:-2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "guess_image.to_csv(DATA_PATH+'image_guess.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "guess_image['real_image_top']=complete_data['image_top_1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item_id</th>\n",
       "      <th>Prob_image_top1</th>\n",
       "      <th>Guess_image_top1</th>\n",
       "      <th>Guess_image_top2</th>\n",
       "      <th>Guess_image_top3</th>\n",
       "      <th>real_image_top</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>b912c3c6a6ad</td>\n",
       "      <td>0.805290</td>\n",
       "      <td>1008</td>\n",
       "      <td>1009</td>\n",
       "      <td>75</td>\n",
       "      <td>1008.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2dac0150717d</td>\n",
       "      <td>0.403171</td>\n",
       "      <td>1522</td>\n",
       "      <td>1496</td>\n",
       "      <td>1489</td>\n",
       "      <td>692.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ba83aefab5dc</td>\n",
       "      <td>0.670797</td>\n",
       "      <td>3042</td>\n",
       "      <td>3039</td>\n",
       "      <td>3040</td>\n",
       "      <td>3032.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>02996f1dd2ea</td>\n",
       "      <td>0.903954</td>\n",
       "      <td>796</td>\n",
       "      <td>1133</td>\n",
       "      <td>1442</td>\n",
       "      <td>796.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7c90be56d2ab</td>\n",
       "      <td>0.414640</td>\n",
       "      <td>1108</td>\n",
       "      <td>2264</td>\n",
       "      <td>2262</td>\n",
       "      <td>2264.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>51e0962387f7</td>\n",
       "      <td>0.954151</td>\n",
       "      <td>796</td>\n",
       "      <td>1133</td>\n",
       "      <td>999</td>\n",
       "      <td>796.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>c4f260a2b48a</td>\n",
       "      <td>0.761278</td>\n",
       "      <td>1400</td>\n",
       "      <td>1383</td>\n",
       "      <td>1197</td>\n",
       "      <td>2823.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>6b71309d6a8a</td>\n",
       "      <td>0.584889</td>\n",
       "      <td>567</td>\n",
       "      <td>658</td>\n",
       "      <td>580</td>\n",
       "      <td>567.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>c5b969cb63a2</td>\n",
       "      <td>0.145360</td>\n",
       "      <td>404</td>\n",
       "      <td>572</td>\n",
       "      <td>399</td>\n",
       "      <td>415.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>b1570962e68c</td>\n",
       "      <td>0.583316</td>\n",
       "      <td>88</td>\n",
       "      <td>85</td>\n",
       "      <td>86</td>\n",
       "      <td>46.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>d5480bb4a6e4</td>\n",
       "      <td>0.344622</td>\n",
       "      <td>2219</td>\n",
       "      <td>2220</td>\n",
       "      <td>2222</td>\n",
       "      <td>1396.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>86f41f50d8c1</td>\n",
       "      <td>0.566575</td>\n",
       "      <td>567</td>\n",
       "      <td>658</td>\n",
       "      <td>580</td>\n",
       "      <td>119.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>645237cb3601</td>\n",
       "      <td>0.294405</td>\n",
       "      <td>1040</td>\n",
       "      <td>2285</td>\n",
       "      <td>1050</td>\n",
       "      <td>1040.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>df2116f34563</td>\n",
       "      <td>0.883681</td>\n",
       "      <td>2849</td>\n",
       "      <td>2844</td>\n",
       "      <td>2847</td>\n",
       "      <td>2849.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>a97943ae8158</td>\n",
       "      <td>0.376526</td>\n",
       "      <td>2097</td>\n",
       "      <td>2135</td>\n",
       "      <td>2162</td>\n",
       "      <td>2133.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>4b6abd0a5921</td>\n",
       "      <td>0.131831</td>\n",
       "      <td>404</td>\n",
       "      <td>399</td>\n",
       "      <td>572</td>\n",
       "      <td>408.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>7896ef8fe482</td>\n",
       "      <td>0.377180</td>\n",
       "      <td>2264</td>\n",
       "      <td>1108</td>\n",
       "      <td>2262</td>\n",
       "      <td>1118.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>7882b1e77748</td>\n",
       "      <td>0.994342</td>\n",
       "      <td>983</td>\n",
       "      <td>834</td>\n",
       "      <td>2277</td>\n",
       "      <td>983.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>071e1ed13c5c</td>\n",
       "      <td>0.291418</td>\n",
       "      <td>545</td>\n",
       "      <td>95</td>\n",
       "      <td>510</td>\n",
       "      <td>95.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0658628930d4</td>\n",
       "      <td>0.135079</td>\n",
       "      <td>2219</td>\n",
       "      <td>1191</td>\n",
       "      <td>2218</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>ea12aec32ec3</td>\n",
       "      <td>0.375245</td>\n",
       "      <td>2219</td>\n",
       "      <td>2220</td>\n",
       "      <td>2218</td>\n",
       "      <td>2011.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>838a82cec0a6</td>\n",
       "      <td>0.474197</td>\n",
       "      <td>334</td>\n",
       "      <td>227</td>\n",
       "      <td>354</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>de310e6aae86</td>\n",
       "      <td>0.308636</td>\n",
       "      <td>2264</td>\n",
       "      <td>1118</td>\n",
       "      <td>2262</td>\n",
       "      <td>2264.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>08b24e170109</td>\n",
       "      <td>0.637738</td>\n",
       "      <td>87</td>\n",
       "      <td>92</td>\n",
       "      <td>93</td>\n",
       "      <td>87.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>065a4daba35f</td>\n",
       "      <td>0.281356</td>\n",
       "      <td>2029</td>\n",
       "      <td>2041</td>\n",
       "      <td>2036</td>\n",
       "      <td>843.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>990113ae4f1c</td>\n",
       "      <td>0.175121</td>\n",
       "      <td>927</td>\n",
       "      <td>875</td>\n",
       "      <td>984</td>\n",
       "      <td>957.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>78164bc09657</td>\n",
       "      <td>0.277848</td>\n",
       "      <td>1420</td>\n",
       "      <td>1422</td>\n",
       "      <td>1424</td>\n",
       "      <td>1420.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>fbe29970a8a5</td>\n",
       "      <td>0.223426</td>\n",
       "      <td>438</td>\n",
       "      <td>501</td>\n",
       "      <td>421</td>\n",
       "      <td>436.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>71d9399b59a2</td>\n",
       "      <td>0.127755</td>\n",
       "      <td>387</td>\n",
       "      <td>399</td>\n",
       "      <td>404</td>\n",
       "      <td>618.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>4941f0385575</td>\n",
       "      <td>0.441062</td>\n",
       "      <td>41</td>\n",
       "      <td>44</td>\n",
       "      <td>42</td>\n",
       "      <td>63.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011832</th>\n",
       "      <td>df8001ca5897</td>\n",
       "      <td>0.884544</td>\n",
       "      <td>1433</td>\n",
       "      <td>1439</td>\n",
       "      <td>1419</td>\n",
       "      <td>1433.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011833</th>\n",
       "      <td>0455281c86fb</td>\n",
       "      <td>0.411799</td>\n",
       "      <td>2263</td>\n",
       "      <td>2262</td>\n",
       "      <td>2281</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011834</th>\n",
       "      <td>482d3253c9f1</td>\n",
       "      <td>0.398226</td>\n",
       "      <td>37</td>\n",
       "      <td>31</td>\n",
       "      <td>35</td>\n",
       "      <td>31.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011835</th>\n",
       "      <td>9278e7c14cd0</td>\n",
       "      <td>0.116171</td>\n",
       "      <td>386</td>\n",
       "      <td>387</td>\n",
       "      <td>403</td>\n",
       "      <td>386.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011836</th>\n",
       "      <td>9041d0340b49</td>\n",
       "      <td>0.716720</td>\n",
       "      <td>667</td>\n",
       "      <td>51</td>\n",
       "      <td>52</td>\n",
       "      <td>667.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011837</th>\n",
       "      <td>872c382ce446</td>\n",
       "      <td>0.772263</td>\n",
       "      <td>44</td>\n",
       "      <td>46</td>\n",
       "      <td>93</td>\n",
       "      <td>44.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011838</th>\n",
       "      <td>67448ad8941c</td>\n",
       "      <td>0.044597</td>\n",
       "      <td>2281</td>\n",
       "      <td>2263</td>\n",
       "      <td>231</td>\n",
       "      <td>1938.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011839</th>\n",
       "      <td>6ffaf4c20469</td>\n",
       "      <td>0.365348</td>\n",
       "      <td>1029</td>\n",
       "      <td>2557</td>\n",
       "      <td>861</td>\n",
       "      <td>1029.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011840</th>\n",
       "      <td>acc46dbda733</td>\n",
       "      <td>0.630082</td>\n",
       "      <td>695</td>\n",
       "      <td>1242</td>\n",
       "      <td>703</td>\n",
       "      <td>695.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011841</th>\n",
       "      <td>eb33cd6dac70</td>\n",
       "      <td>0.224077</td>\n",
       "      <td>438</td>\n",
       "      <td>421</td>\n",
       "      <td>501</td>\n",
       "      <td>421.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011842</th>\n",
       "      <td>f9db673cb425</td>\n",
       "      <td>0.327219</td>\n",
       "      <td>81</td>\n",
       "      <td>375</td>\n",
       "      <td>378</td>\n",
       "      <td>81.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011843</th>\n",
       "      <td>32727c2ed7e5</td>\n",
       "      <td>0.848360</td>\n",
       "      <td>2419</td>\n",
       "      <td>2418</td>\n",
       "      <td>2417</td>\n",
       "      <td>2419.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011844</th>\n",
       "      <td>2e6f289d2676</td>\n",
       "      <td>0.178522</td>\n",
       "      <td>386</td>\n",
       "      <td>387</td>\n",
       "      <td>403</td>\n",
       "      <td>395.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011845</th>\n",
       "      <td>58fa2c39f791</td>\n",
       "      <td>0.758166</td>\n",
       "      <td>2963</td>\n",
       "      <td>2952</td>\n",
       "      <td>2958</td>\n",
       "      <td>2963.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011846</th>\n",
       "      <td>0e1a370c12c7</td>\n",
       "      <td>0.307041</td>\n",
       "      <td>492</td>\n",
       "      <td>499</td>\n",
       "      <td>489</td>\n",
       "      <td>492.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011847</th>\n",
       "      <td>cc4f7fd3d2f2</td>\n",
       "      <td>0.572544</td>\n",
       "      <td>1327</td>\n",
       "      <td>1283</td>\n",
       "      <td>1302</td>\n",
       "      <td>1327.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011848</th>\n",
       "      <td>29a342aa8508</td>\n",
       "      <td>0.111884</td>\n",
       "      <td>1267</td>\n",
       "      <td>1253</td>\n",
       "      <td>1249</td>\n",
       "      <td>1223.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011849</th>\n",
       "      <td>fce6b0de65f8</td>\n",
       "      <td>0.409035</td>\n",
       "      <td>528</td>\n",
       "      <td>97</td>\n",
       "      <td>649</td>\n",
       "      <td>545.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011850</th>\n",
       "      <td>dae17c1850b0</td>\n",
       "      <td>0.281572</td>\n",
       "      <td>2263</td>\n",
       "      <td>2262</td>\n",
       "      <td>2281</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011851</th>\n",
       "      <td>549b1c9354e3</td>\n",
       "      <td>0.146863</td>\n",
       "      <td>448</td>\n",
       "      <td>468</td>\n",
       "      <td>638</td>\n",
       "      <td>468.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011852</th>\n",
       "      <td>0915772bb21c</td>\n",
       "      <td>0.159748</td>\n",
       "      <td>415</td>\n",
       "      <td>618</td>\n",
       "      <td>413</td>\n",
       "      <td>573.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011853</th>\n",
       "      <td>d8984ced6639</td>\n",
       "      <td>0.293102</td>\n",
       "      <td>2219</td>\n",
       "      <td>2220</td>\n",
       "      <td>2222</td>\n",
       "      <td>2219.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011854</th>\n",
       "      <td>e7c68be28a03</td>\n",
       "      <td>0.112787</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>742.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011855</th>\n",
       "      <td>a96a4c5ad75a</td>\n",
       "      <td>0.365980</td>\n",
       "      <td>81</td>\n",
       "      <td>375</td>\n",
       "      <td>378</td>\n",
       "      <td>375.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011856</th>\n",
       "      <td>fdcd9910edf3</td>\n",
       "      <td>0.412944</td>\n",
       "      <td>1118</td>\n",
       "      <td>2262</td>\n",
       "      <td>2264</td>\n",
       "      <td>2264.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011857</th>\n",
       "      <td>9f2200aed300</td>\n",
       "      <td>0.841738</td>\n",
       "      <td>2939</td>\n",
       "      <td>2933</td>\n",
       "      <td>2920</td>\n",
       "      <td>2939.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011858</th>\n",
       "      <td>70813f518de4</td>\n",
       "      <td>0.808263</td>\n",
       "      <td>2951</td>\n",
       "      <td>2949</td>\n",
       "      <td>2963</td>\n",
       "      <td>2951.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011859</th>\n",
       "      <td>a22a2eeb5dd2</td>\n",
       "      <td>0.149654</td>\n",
       "      <td>404</td>\n",
       "      <td>572</td>\n",
       "      <td>399</td>\n",
       "      <td>572.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011860</th>\n",
       "      <td>ed7fbb0733c1</td>\n",
       "      <td>0.430281</td>\n",
       "      <td>1886</td>\n",
       "      <td>2267</td>\n",
       "      <td>2217</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011861</th>\n",
       "      <td>d374d332992f</td>\n",
       "      <td>0.959426</td>\n",
       "      <td>1255</td>\n",
       "      <td>1277</td>\n",
       "      <td>1240</td>\n",
       "      <td>1255.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2011862 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              item_id  Prob_image_top1  Guess_image_top1  Guess_image_top2  \\\n",
       "0        b912c3c6a6ad         0.805290              1008              1009   \n",
       "1        2dac0150717d         0.403171              1522              1496   \n",
       "2        ba83aefab5dc         0.670797              3042              3039   \n",
       "3        02996f1dd2ea         0.903954               796              1133   \n",
       "4        7c90be56d2ab         0.414640              1108              2264   \n",
       "5        51e0962387f7         0.954151               796              1133   \n",
       "6        c4f260a2b48a         0.761278              1400              1383   \n",
       "7        6b71309d6a8a         0.584889               567               658   \n",
       "8        c5b969cb63a2         0.145360               404               572   \n",
       "9        b1570962e68c         0.583316                88                85   \n",
       "10       d5480bb4a6e4         0.344622              2219              2220   \n",
       "11       86f41f50d8c1         0.566575               567               658   \n",
       "12       645237cb3601         0.294405              1040              2285   \n",
       "13       df2116f34563         0.883681              2849              2844   \n",
       "14       a97943ae8158         0.376526              2097              2135   \n",
       "15       4b6abd0a5921         0.131831               404               399   \n",
       "16       7896ef8fe482         0.377180              2264              1108   \n",
       "17       7882b1e77748         0.994342               983               834   \n",
       "18       071e1ed13c5c         0.291418               545                95   \n",
       "19       0658628930d4         0.135079              2219              1191   \n",
       "20       ea12aec32ec3         0.375245              2219              2220   \n",
       "21       838a82cec0a6         0.474197               334               227   \n",
       "22       de310e6aae86         0.308636              2264              1118   \n",
       "23       08b24e170109         0.637738                87                92   \n",
       "24       065a4daba35f         0.281356              2029              2041   \n",
       "25       990113ae4f1c         0.175121               927               875   \n",
       "26       78164bc09657         0.277848              1420              1422   \n",
       "27       fbe29970a8a5         0.223426               438               501   \n",
       "28       71d9399b59a2         0.127755               387               399   \n",
       "29       4941f0385575         0.441062                41                44   \n",
       "...               ...              ...               ...               ...   \n",
       "2011832  df8001ca5897         0.884544              1433              1439   \n",
       "2011833  0455281c86fb         0.411799              2263              2262   \n",
       "2011834  482d3253c9f1         0.398226                37                31   \n",
       "2011835  9278e7c14cd0         0.116171               386               387   \n",
       "2011836  9041d0340b49         0.716720               667                51   \n",
       "2011837  872c382ce446         0.772263                44                46   \n",
       "2011838  67448ad8941c         0.044597              2281              2263   \n",
       "2011839  6ffaf4c20469         0.365348              1029              2557   \n",
       "2011840  acc46dbda733         0.630082               695              1242   \n",
       "2011841  eb33cd6dac70         0.224077               438               421   \n",
       "2011842  f9db673cb425         0.327219                81               375   \n",
       "2011843  32727c2ed7e5         0.848360              2419              2418   \n",
       "2011844  2e6f289d2676         0.178522               386               387   \n",
       "2011845  58fa2c39f791         0.758166              2963              2952   \n",
       "2011846  0e1a370c12c7         0.307041               492               499   \n",
       "2011847  cc4f7fd3d2f2         0.572544              1327              1283   \n",
       "2011848  29a342aa8508         0.111884              1267              1253   \n",
       "2011849  fce6b0de65f8         0.409035               528                97   \n",
       "2011850  dae17c1850b0         0.281572              2263              2262   \n",
       "2011851  549b1c9354e3         0.146863               448               468   \n",
       "2011852  0915772bb21c         0.159748               415               618   \n",
       "2011853  d8984ced6639         0.293102              2219              2220   \n",
       "2011854  e7c68be28a03         0.112787                 1                 4   \n",
       "2011855  a96a4c5ad75a         0.365980                81               375   \n",
       "2011856  fdcd9910edf3         0.412944              1118              2262   \n",
       "2011857  9f2200aed300         0.841738              2939              2933   \n",
       "2011858  70813f518de4         0.808263              2951              2949   \n",
       "2011859  a22a2eeb5dd2         0.149654               404               572   \n",
       "2011860  ed7fbb0733c1         0.430281              1886              2267   \n",
       "2011861  d374d332992f         0.959426              1255              1277   \n",
       "\n",
       "         Guess_image_top3  real_image_top  \n",
       "0                      75          1008.0  \n",
       "1                    1489           692.0  \n",
       "2                    3040          3032.0  \n",
       "3                    1442           796.0  \n",
       "4                    2262          2264.0  \n",
       "5                     999           796.0  \n",
       "6                    1197          2823.0  \n",
       "7                     580           567.0  \n",
       "8                     399           415.0  \n",
       "9                      86            46.0  \n",
       "10                   2222          1396.0  \n",
       "11                    580           119.0  \n",
       "12                   1050          1040.0  \n",
       "13                   2847          2849.0  \n",
       "14                   2162          2133.0  \n",
       "15                    572           408.0  \n",
       "16                   2262          1118.0  \n",
       "17                   2277           983.0  \n",
       "18                    510            95.0  \n",
       "19                   2218             NaN  \n",
       "20                   2218          2011.0  \n",
       "21                    354             NaN  \n",
       "22                   2262          2264.0  \n",
       "23                     93            87.0  \n",
       "24                   2036           843.0  \n",
       "25                    984           957.0  \n",
       "26                   1424          1420.0  \n",
       "27                    421           436.0  \n",
       "28                    404           618.0  \n",
       "29                     42            63.0  \n",
       "...                   ...             ...  \n",
       "2011832              1419          1433.0  \n",
       "2011833              2281             NaN  \n",
       "2011834                35            31.0  \n",
       "2011835               403           386.0  \n",
       "2011836                52           667.0  \n",
       "2011837                93            44.0  \n",
       "2011838               231          1938.0  \n",
       "2011839               861          1029.0  \n",
       "2011840               703           695.0  \n",
       "2011841               501           421.0  \n",
       "2011842               378            81.0  \n",
       "2011843              2417          2419.0  \n",
       "2011844               403           395.0  \n",
       "2011845              2958          2963.0  \n",
       "2011846               489           492.0  \n",
       "2011847              1302          1327.0  \n",
       "2011848              1249          1223.0  \n",
       "2011849               649           545.0  \n",
       "2011850              2281             NaN  \n",
       "2011851               638           468.0  \n",
       "2011852               413           573.0  \n",
       "2011853              2222          2219.0  \n",
       "2011854                 2           742.0  \n",
       "2011855               378           375.0  \n",
       "2011856              2264          2264.0  \n",
       "2011857              2920          2939.0  \n",
       "2011858              2963          2951.0  \n",
       "2011859               399           572.0  \n",
       "2011860              2217             NaN  \n",
       "2011861              1240          1255.0  \n",
       "\n",
       "[2011862 rows x 6 columns]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "guess_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
