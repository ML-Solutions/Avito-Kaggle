{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import time\n",
    "import re\n",
    "import gc\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.sparse import hstack, csr_matrix\n",
    "pd.options.display.max_columns = 999\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "import catboost as cb\n",
    "\n",
    "from hyperopt import tpe, hp, fmin, Trials\n",
    "from IPython.display import clear_output\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('dark_background')\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def downcast_dtypes(df):\n",
    "    '''\n",
    "        Changes column types in the dataframe: \n",
    "                \n",
    "        `float64` type to `float32`\n",
    "        `int64`   type to `int32`\n",
    "    '''\n",
    "    \n",
    "    # Select columns to downcast\n",
    "    float_cols = [c for c in df if df[c].dtype == \"float64\"]\n",
    "    int_cols =   [c for c in df if df[c].dtype == \"int64\"]\n",
    "    \n",
    "    # Downcast\n",
    "    df[float_cols] = df[float_cols].astype(np.float32)\n",
    "    df[int_cols]   = df[int_cols].astype(np.int32)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = 'E:/Kaggle/Avito/'\n",
    "\n",
    "seed = 32\n",
    "FOLDS = 5\n",
    "min_class_cat = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(DATA_PATH+'train.csv')\n",
    "test = pd.read_csv(DATA_PATH+'test.csv')\n",
    "guess_image = pd.read_csv(DATA_PATH+'image_guess.csv')\n",
    "price_guess  = pd.read_csv(DATA_PATH+'price_guess.csv')\n",
    "param_guess  = pd.read_csv(DATA_PATH+'param_guess.csv')\n",
    "param2_guess  = pd.read_csv(DATA_PATH+'param2_guess.csv')\n",
    "\n",
    "images0 = pd.read_csv(DATA_PATH+'image0_features.csv')\n",
    "images1 = pd.read_csv(DATA_PATH+'image1_features.csv')\n",
    "images2 = pd.read_csv(DATA_PATH+'image2_features.csv')\n",
    "images3 = pd.read_csv(DATA_PATH+'image3_features.csv')\n",
    "images4 = pd.read_csv(DATA_PATH+'image4_features.csv')\n",
    "imagestest = pd.read_csv(DATA_PATH+'imagetest_features.csv')\n",
    "imagesdata = pd.concat([images0,images1,images2,images3,images4,imagestest],axis=0)\n",
    "del images0, images1, images2, images3, images4, imagestest\n",
    "\n",
    "images_pred0 = pd.read_csv(DATA_PATH+'Image_preds0.csv')\n",
    "images_pred1 = pd.read_csv(DATA_PATH+'Image_preds1.csv')\n",
    "images_pred2 = pd.read_csv(DATA_PATH+'Image_preds2.csv')\n",
    "images_pred3 = pd.read_csv(DATA_PATH+'Image_preds3.csv')\n",
    "images_pred4 = pd.read_csv(DATA_PATH+'Image_preds4.csv')\n",
    "imagestest_pred = pd.read_csv(DATA_PATH+'Image_predstest.csv')\n",
    "imagesdata_pred = pd.concat([images_pred0,images_pred1,images_pred2,images_pred3,images_pred4,imagestest_pred],axis=0)\n",
    "del images_pred0, images_pred1, images_pred2, images_pred3, images_pred4, imagestest_pred\n",
    "\n",
    "user_agg = pd.read_csv(DATA_PATH+'user_aggregated_features.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = KFold(FOLDS,random_state=seed,shuffle=True)\n",
    "Fold = 0\n",
    "for train_index, test_index in kf.split(train):\n",
    "    train.loc[test_index,'Fold']=Fold\n",
    "    Fold += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_data = pd.concat([train,test],axis=0,ignore_index=True)\n",
    "complete_data = pd.merge(complete_data,guess_image,how='left')\n",
    "complete_data = pd.merge(complete_data,price_guess,how='left')\n",
    "complete_data = pd.merge(complete_data,param_guess,how='left')\n",
    "complete_data = pd.merge(complete_data,param2_guess,how='left')\n",
    "complete_data = pd.merge(complete_data,imagesdata,how='left')\n",
    "complete_data = pd.merge(complete_data,imagesdata_pred,how='left')\n",
    "complete_data = pd.merge(complete_data,user_agg,how='left',on='user_id')\n",
    "del guess_image, price_guess, param_guess, param2_guess, imagesdata, imagesdata_pred, user_agg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_data['missing_param_1'] = complete_data['param_1'].isnull().astype(int)\n",
    "complete_data['missing_param_2'] = complete_data['param_2'].isnull().astype(int)\n",
    "complete_data['missing_param_3'] = complete_data['param_3'].isnull().astype(int)\n",
    "complete_data['missing_desc'] = complete_data['description'].isnull().astype(int)\n",
    "complete_data['missing_price'] = complete_data['price'].isnull().astype(int)\n",
    "complete_data['missing_image'] = complete_data['image'].isnull().astype(int)\n",
    "complete_data['number_missings'] = complete_data['missing_param_1']+complete_data['missing_param_2']+complete_data['missing_image']+\\\n",
    "                                    complete_data['missing_param_3']+complete_data['missing_desc']+complete_data['missing_price'] \n",
    "del complete_data['missing_param_1'] \n",
    "del complete_data['missing_param_2'] \n",
    "del complete_data['missing_param_3']\n",
    "del complete_data['missing_desc'] \n",
    "del complete_data['missing_price'] \n",
    "del complete_data['missing_image']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = complete_data.groupby(['user_id'],as_index=False).agg({'item_id':'count'}).rename(columns={'item_id':'count_item'})\n",
    "big_users = set(temp[temp['count_item']>=5]['user_id'])\n",
    "complete_data['user_id'] = np.where(complete_data['user_id'].isin(big_users),complete_data['user_id'],'SmallUser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_data['log_price']=np.log(complete_data['price']+0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_data['city_counts']=complete_data.groupby(['city'])['item_id'].transform('count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_data['region_counts']=complete_data.groupby(['region'])['item_id'].transform('count')\n",
    "complete_data['category_name_counts']=complete_data.groupby(['category_name'])['item_id'].transform('count')\n",
    "complete_data['Guess_image_top1_counts']=complete_data.groupby(['Guess_image_top1'])['item_id'].transform('count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_data['price'].fillna(-999,inplace=True)\n",
    "complete_data['log_price'].fillna(-999,inplace=True)\n",
    "complete_data['price_10']=np.where(complete_data['price']>=0, (complete_data['price'].astype(int)//10).astype(str).apply(lambda x: x[-1]),-999).astype(int)\n",
    "complete_data['price_100']=np.where(complete_data['price']>=0, (complete_data['price'].astype(int)//100).astype(str).apply(lambda x: x[-1]),-999).astype(int)\n",
    "complete_data['price_1000']=np.where(complete_data['price']>=0, (complete_data['price'].astype(int)//1000).astype(str).apply(lambda x: x[-1]),-999).astype(int)\n",
    "complete_data['price_10000']=np.where(complete_data['price']>=0, (complete_data['price'].astype(int)//10000).astype(str).apply(lambda x: x[-1]),-999).astype(int)\n",
    "complete_data['price_100000']=np.where(complete_data['price']>=0, (complete_data['price'].astype(int)//100000).astype(str).apply(lambda x: x[-1]),-999).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_data['log_item_seq']=np.log(0.01+complete_data['item_seq_number'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_data['param_1'].fillna('Unknown',inplace=True)\n",
    "complete_data['param_2'].fillna('Unknown',inplace=True)\n",
    "complete_data['param_3'].fillna('Unknown',inplace=True)\n",
    "complete_data['image_top_1'].fillna('Unknown',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = train.groupby(['city'],as_index=False).agg({'item_id':'count'}).rename(columns={'item_id':'count_item'})\n",
    "big_cities = set(temp[temp['count_item']>=min_class_cat]['city'])\n",
    "complete_data['city_clean'] = np.where(complete_data['city'].isin(big_cities),complete_data['city'],'SmallCity')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "uppercase_regex = re.compile(r'[A-ZА-Я]')\n",
    "symbols_regex = re.compile(r'[^a-zA-ZА-Я0-9а-я]')\n",
    "digits_regex = re.compile(r'[0-9]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_data['title_number_uppercase'] = complete_data['title'].str.count(uppercase_regex)\n",
    "complete_data['title_number_symbols'] = complete_data['title'].str.count(symbols_regex)\n",
    "complete_data['title_number_digits'] = complete_data['title'].str.count(digits_regex)\n",
    "complete_data['title_len_chars'] = complete_data['title'].apply(lambda x: len(str(x)))\n",
    "complete_data['title_len_words'] = complete_data['title'].str.split().apply(lambda x: len(str(x)))\n",
    "complete_data['title_unique'] = complete_data['title'].str.split().apply(lambda x: len(set(str(x))))\n",
    "complete_data['share_unique_title'] = complete_data['title_unique']/complete_data['title_len_words']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_data['desc_number_uppercase'] = complete_data['description'].str.count(uppercase_regex)\n",
    "complete_data['desc_number_symbols'] = complete_data['description'].str.count(symbols_regex)\n",
    "complete_data['desc_number_digits'] = complete_data['description'].str.count(digits_regex) #should do similar stuff for param\n",
    "complete_data['desc_len_char']=complete_data['description'].apply(lambda x: len(str(x)))\n",
    "complete_data['desc_len_words']=complete_data['description'].str.split().apply(lambda x: len(str(x)))\n",
    "complete_data['desc_unique'] = complete_data['description'].str.split().apply(lambda x: len(set(str(x))))\n",
    "complete_data['share_unique_desc'] = complete_data['desc_unique']/complete_data['desc_len_words']\n",
    "complete_data['desc_rows'] = complete_data['description'].astype(str).apply(lambda x: x.count('/\\n'))\n",
    "complete_data['r_title_desc'] = complete_data['title_len_chars']/(complete_data['desc_len_char']+1)\n",
    "complete_data['desc_number_uppercase'].fillna(-999,inplace=True)\n",
    "complete_data['desc_number_symbols'].fillna(-999,inplace=True)\n",
    "complete_data['desc_number_digits'].fillna(-999,inplace=True)\n",
    "complete_data['desc_len_char'].fillna(-999,inplace=True)\n",
    "complete_data['desc_len_words'].fillna(-999,inplace=True)\n",
    "complete_data['desc_unique'].fillna(-999,inplace=True)\n",
    "complete_data['share_unique_desc'].fillna(-999,inplace=True)\n",
    "complete_data['desc_rows'].fillna(-999,inplace=True)\n",
    "complete_data['r_title_desc'].fillna(-999,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "for var in ['img_size', 'lightness','darkness','pixel_width','avg_red','avg_green','avg_blue','width','height','blurness']:\n",
    "    complete_data[var].fillna(-999,inplace=True)\n",
    "for var in ['usermean_days_up_sum','usermean_days_up_count','usermean_days_up_avg','usermean_days_until_activation_sum','usermean_days_until_activation_avg',\n",
    "            'userstd_days_up_sum','userstd_days_up_count','userstd_days_up_avg','userstd_days_until_activation_sum','userstd_days_until_activation_avg','usermedian_days_up_sum',\n",
    "            'usermedian_days_up_count','usermedian_days_up_avg','usermedian_days_until_activation_sum','usermedian_days_until_activation_avg','n_user_items']:\n",
    "    complete_data[var].fillna(-999,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "english_stopwords = set(stopwords.words('english'))\n",
    "russian_stopwords = set(stopwords.words('russian'))\n",
    "russian_stopwords = russian_stopwords.union(english_stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Svd Title\n",
    "n_components_title = 25 #best between 20 and 30\n",
    "colnames_svdtitle = ['svd_title_'+str(x) for x in range(n_components_title)]\n",
    "wordVectTitle = TfidfVectorizer(min_df=2, #Reduce some overfitting (to try in hyper opt)\n",
    "                                max_df=0.5,\n",
    "                                ngram_range=(1,3),\n",
    "                                stop_words = russian_stopwords\n",
    "                               )\n",
    "title_sparse = wordVectTitle.fit_transform(complete_data['title'])\n",
    "svd_title = TruncatedSVD(n_components=n_components_title)\n",
    "title_sparse_proj  = svd_title.fit_transform(title_sparse).astype('float32')\n",
    "complete_data = pd.concat([complete_data,pd.DataFrame(title_sparse_proj,columns=colnames_svdtitle)],axis=1)\n",
    "del title_sparse_proj, title_sparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Svd Description\n",
    "n_components_desc = 30 #best between 35 and 50\n",
    "colnames_svddesc = ['svd_desc_'+str(x) for x in range(n_components_desc)]\n",
    "wordVectDesc = TfidfVectorizer(min_df=2,\n",
    "                                max_df=0.5,\n",
    "                                ngram_range=(1,2),\n",
    "                                stop_words = stopwords.words('russian')\n",
    "                               )\n",
    "desc_sparse = wordVectDesc.fit_transform(complete_data['description'].astype(str))\n",
    "svd_desc = TruncatedSVD(n_components=n_components_desc)\n",
    "desc_sparse_proj  = svd_desc.fit_transform(desc_sparse).astype('float32')\n",
    "complete_data = pd.concat([complete_data,pd.DataFrame(desc_sparse_proj,columns=colnames_svddesc)],axis=1)\n",
    "del desc_sparse_proj, desc_sparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Svd Params\n",
    "n_components_params = 15 \n",
    "colnames_svdparams = ['svd_params_'+str(x) for x in range(n_components_params)]\n",
    "complete_data['params'] = complete_data['param_1']+' '+complete_data['param_2']+' '+complete_data['param_3']\n",
    "\n",
    "wordVectParams = TfidfVectorizer(ngram_range=(1,3),\n",
    "                                stop_words = stopwords.words('russian')\n",
    "                               )\n",
    "params_sparse = wordVectParams.fit_transform(complete_data['params'])\n",
    "svd_params = TruncatedSVD(n_components=n_components_params)\n",
    "params_sparse_proj  = svd_params.fit_transform(params_sparse)\n",
    "complete_data = pd.concat([complete_data,pd.DataFrame(params_sparse_proj,columns=colnames_svdparams)],axis=1)\n",
    "del params_sparse_proj, params_sparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_data['labels_all'] = (complete_data['Res50_label1'].astype(str)+' '+complete_data['Xcept_label1'].astype(str)+' '+complete_data['Incept_label1'].astype(str)+' '+\n",
    "                               complete_data['Res50_label2'].astype(str)+' '+complete_data['Xcept_label2'].astype(str)+' '+complete_data['Incept_label2'].astype(str)+' '+\n",
    "                               complete_data['Res50_label3'].astype(str)+' '+complete_data['Xcept_label3'].astype(str)+' '+complete_data['Incept_label3'].astype(str))\n",
    "n_components_labels = 15 \n",
    "colnames_svdlabels = ['svd_labels_'+str(x) for x in range(n_components_labels)]\n",
    "\n",
    "wordVectLabels = CountVectorizer(lowercase=True,analyzer='word',token_pattern=r'\\w+',\n",
    "                             ngram_range=(1,1),dtype=np.float32,min_df=2,max_features=15000)\n",
    "labels_sparse = wordVectLabels.fit_transform(complete_data['labels_all'].astype(str))\n",
    "svd_labels = TruncatedSVD(n_components=n_components_labels)\n",
    "labels_sparse_proj  = svd_labels.fit_transform(labels_sparse)\n",
    "complete_data = pd.concat([complete_data,pd.DataFrame(labels_sparse_proj,columns=colnames_svdlabels)],axis=1)\n",
    "del labels_sparse_proj, labels_sparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Fold                508438\n",
       "deal_probability    508438\n",
       "description         116276\n",
       "image               155197\n",
       "Res50_label1        155201\n",
       "Res50_label2        155201\n",
       "Res50_label3        155201\n",
       "Res50_label4        155201\n",
       "Res50_label5        155201\n",
       "Res50_score1        155201\n",
       "Res50_score2        155201\n",
       "Res50_score3        155201\n",
       "Res50_score4        155201\n",
       "Res50_score5        155201\n",
       "Xcept_label1        155201\n",
       "Xcept_label2        155201\n",
       "Xcept_label3        155201\n",
       "Xcept_label4        155201\n",
       "Xcept_label5        155201\n",
       "Xcept_score1        155201\n",
       "Xcept_score2        155201\n",
       "Xcept_score3        155201\n",
       "Xcept_score4        155201\n",
       "Xcept_score5        155201\n",
       "Incept_label1       155201\n",
       "Incept_label2       155201\n",
       "Incept_label3       155201\n",
       "Incept_label4       155201\n",
       "Incept_label5       155201\n",
       "Incept_score1       155201\n",
       "Incept_score2       155201\n",
       "Incept_score3       155201\n",
       "Incept_score4       155201\n",
       "Incept_score5       155201\n",
       "KP_len              155201\n",
       "dtype: int64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp = complete_data.isnull().sum()\n",
    "temp[temp>0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 2011862 entries, 0 to 2011861\n",
      "Columns: 205 entries, Fold to svd_labels_14\n",
      "dtypes: float32(142), int32(24), object(39)\n",
      "memory usage: 1.8+ GB\n"
     ]
    }
   ],
   "source": [
    "complete_data = downcast_dtypes(complete_data)\n",
    "complete_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "49"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "categoricals = ['param_1','image_top_1','city_clean','user_type']\n",
    "categoricals += ['Guess_image_top1','Guess_image_top2','category_name']\n",
    "categoricals += ['param_2','param_3']\n",
    "categoricals += ['user_id']\n",
    "categoricals += ['price_10','price_100','price_1000', 'price_10000']\n",
    "categoricals += ['Guess_param_top1', 'Guess_param_top2','Guess_param_top3']\n",
    "categoricals += ['Guess_param2_top1', 'Guess_param2_top2']\n",
    "\n",
    "numericals = ['log_price','log_item_seq','Prob_image_top1','number_missings','city_counts']\n",
    "numericals += ['title_number_uppercase','title_number_symbols','title_number_digits','title_len_chars','title_len_words','title_unique','share_unique_title']\n",
    "numericals += ['desc_number_uppercase','desc_number_symbols','desc_number_digits','desc_len_char','desc_len_words','desc_unique','share_unique_desc','desc_rows','r_title_desc']\n",
    "numericals += ['Guess_price','Prob_param_top1']\n",
    "numericals += [ 'lightness','darkness','avg_red','avg_green','avg_blue','width','height','blurness']\n",
    "\n",
    "numericals += ['usermean_days_up_sum','usermean_days_up_count','usermean_days_up_avg','usermean_days_until_activation_sum','usermean_days_until_activation_avg',\n",
    "            'userstd_days_up_sum','userstd_days_up_count','n_user_items']\n",
    "\n",
    "numericals += colnames_svdtitle\n",
    "numericals += colnames_svddesc\n",
    "numericals += colnames_svdparams\n",
    "numericals += colnames_svdlabels\n",
    "\n",
    "features = categoricals + numericals\n",
    "index_cat = list(range(0,len(categoricals)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "le = LabelEncoder()\n",
    "for col in categoricals:\n",
    "    complete_data[col] = le.fit_transform(complete_data[col].astype(str))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_indexes = np.where(complete_data['deal_probability'].notnull())[0]\n",
    "test_indexes = np.where(complete_data['deal_probability'].isnull())[0]\n",
    "\n",
    "X_all = complete_data[features]\n",
    "\n",
    "X = X_all.iloc[train_indexes,:]\n",
    "X_test = X_all.iloc[test_indexes,:]\n",
    "y = complete_data['deal_probability'][train_indexes].copy()\n",
    "del X_all\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_params = {'eval_metric':'RMSE',\n",
    "              'logging_level':'Silent',\n",
    "              \n",
    "              'depth':13,\n",
    "              'iterations':10000,\n",
    "              'learning_rate':0.10,\n",
    "              'one_hot_max_size':5,\n",
    "              'gpu_ram_part':0.8,\n",
    "              'random_seed':seed,\n",
    "              'task_type':'GPU',\n",
    "              'od_type':\"Iter\",\n",
    "              'calc_feature_importance':False,\n",
    "              'od_wait':50}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.21768447935966204\n"
     ]
    }
   ],
   "source": [
    "predict_test_kfolds = []\n",
    "X_meta = np.zeros((X.shape[0],2))\n",
    "X_meta[:,0]=y\n",
    "X_meta_test = np.zeros((X_test.shape[0],2))\n",
    "\n",
    "feature_importances_split = []\n",
    "predict_test_kfolds = []\n",
    "i=0\n",
    "rmse=[]\n",
    "n_trees =[]\n",
    "\n",
    "start = time()\n",
    "for fold in range(FOLDS):\n",
    "    val_idx =  np.where(complete_data['Fold']==fold)[0]\n",
    "    train_idx = np.where((complete_data['Fold']!=fold) & (complete_data['Fold'].notnull()))[0]\n",
    "    \n",
    "    X_tr = X.iloc[train_idx,:].values\n",
    "    y_tr = y[train_idx]\n",
    "    X_val = X.iloc[val_idx,:].values\n",
    "    y_val = y[val_idx]\n",
    "    \n",
    "    cat_model = cb.CatBoostRegressor(**cat_params)\n",
    "    \n",
    "    cat_model.fit(X=X_tr,y=y_tr,eval_set=(X_val,y_val),cat_features=index_cat,verbose=False,use_best_model=True)\n",
    "\n",
    "    predict_val = cat_model.predict(X_val).clip(0.0,1.0)\n",
    "    r = mean_squared_error(y_val,predict_val)**0.5\n",
    "    X_meta[val_idx,1]=predict_val\n",
    "    \n",
    "    predict_test = cat_model.predict(X_test).clip(0.0,1.0)\n",
    "    predict_test_kfolds.append(predict_test)\n",
    "    \n",
    "    rmse.append(r)\n",
    "    print(r)\n",
    "    n_trees.append(cat_model.tree_count_)\n",
    "\n",
    "avg_rmse = sum(rmse)/len(rmse)\n",
    "avg_trees = sum(n_trees)//len(n_trees)\n",
    "print('Average RMSE',avg_rmse,'Average Trees',avg_trees)\n",
    "print((time()-start)//60,'Minutes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kfold_predictions = np.stack(predict_test_kfolds).mean(axis=0)\n",
    "test['deal_probability'] = kfold_predictions\n",
    "test[['item_id','deal_probability']].to_csv(DATA_PATH+f'{avg_rmse:.5f}_'+'Predictions_Catboostv2.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Meta Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Meta_data = pd.DataFrame(X_meta,columns=['deal_probability','LGB1'])\n",
    "Meta_data.to_csv(DATA_PATH+'Meta_Catboostv2.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
